---
title: "Practical Machine Learning - Predicting Physical Exercise Executions"
author: "MeM"
date: "18 september 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks.

One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, we will use data recorded from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

More information is available from the website http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

The goal of this project is to predict the manner in which the participants did the exercise. This is the classe variable of the training set, which classifies the correct and incorrect outcomes into A, B, C, D, and E categories. This report describes how the model for the project was built, its cross validation, expected out of sample error calculation, and the choices made. It was used successfully to accurately predict 20 different test cases.

## Exploratory data analysis

The data available from the source mentioned in the introduction is imported, while interpreting the miscellaneous NA, #DIV/0! and empty fields as NA.
```{r, echo=TRUE}
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
testing  <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))
```

A quick look at the data and particularly at classe (the variable to bed predicted) results in the following characteristics.
```{r, echo=TRUE}
str(training, list.len=15)
table(training$classe)
prop.table(table(training$classe))
```

A first data clean-up is done by, for example, removing columns 1 to 6 (information and reference columns) and removing columns which consist for a great 
part of NA's.

```{r, echo=TRUE}
## Remove columns 1 & 6
training <- training[, 7:160]
testing  <- testing[, 7:160]
## Remove NA columns
is_data  <- apply(!is.na(training), 2, sum) > 19621  # which is the number of observations
training <- training[, is_data]
testing  <- testing[, is_data]
```

The training set is split into two sets to be used in the cross validation. 60% of the training set is used for training purposes and the remaining 40% is used for the performance measurement of the predictive model.

```{r, echo=TRUE}
library(caret)
set.seed(3141592)
inTrain <- createDataPartition(y=training$classe, p=0.60, list=FALSE)
train1  <- training[inTrain,]
train2  <- training[-inTrain,]
```

train1 is the training data set and contains 11776 observations and train2 is the testing data set and contains 7846 observations. train2 is the blind testset and is only going to be used for accuracy measurements.

```{r, echo=TRUE}
dim(train1)
dim(train2)
```

Both sets contain 53 clean covariates (columns) to build a model for the prediction of the classe variable (54th column).

## Data manipulation

The relative importance of the 53 covariaties is checked using the output of a Random Forest algorithm and then plotted.

```{r, echo=TRUE}
library(randomForest)
set.seed(3141592)
fitModel <- randomForest(classe~., data=train1, importance=TRUE, ntree=100)
varImpPlot(fitModel)
```

The Accuracy and Gini graphs above are used to select the top 10 variables which we'll be used for the predictive model. The 10 covariates are:

* yaw_belt
* num_window
* roll_belt
* magnet_dumbbell_z
* pitch_belt
* pitch_forearm
* magnet_dumbbell_y
* accel_dumbbell_y
* roll_arm
* roll_forearm.

The correlations between these 10 variables are researched. The output below shows the variables having an absolute value correlation above 75%.

```{r, echo=TRUE}
correl = cor(train1[,c("yaw_belt","roll_belt","num_window","pitch_belt","magnet_dumbbell_z","magnet_dumbbell_y","pitch_forearm","accel_dumbbell_y","roll_arm","roll_forearm")])
diag(correl) <- 0
which(abs(correl)>0.75, arr.ind=TRUE)
```

```{r, echo=TRUE}
cor(train1$roll_belt, train1$yaw_belt)
```

Inaccuracy could be introduced by the roll_belt and yaw_belt variables which are highly correlated with each other (above 75%). See output above.

```{r, echo=TRUE}
library(rpart.plot)
fitModel <- rpart(classe~., data=train1, method="class")
prp(fitModel)
```

A quick tree classifier (see plot above) selects roll_belt as the first discriminant among all 53 covariates which indicates it would be better to eliminate yaw_belt, because roll_belt is a "more important" covariate.

To conclude: the model will be built on the remaining 9 variables. By re-running the correlation script, it can be seen that the maximum correlation among these 9 variables is 50.57% which is sufficiently low to ensure a relatively independent set of covariates.

## Data modeling

A Random Forest algorithm is used to build the predictive model. The 9 variables (num_window, roll_belt, magnet_dumbbell_z, pitch_belt, pitch_forearm, magnet_dumbbell_y, accel_dumbbell_y, roll_arm, roll_forearm) determined in the previous step are used as input to predict the classe variable. The data set is large, thus using a small number of folds is justified. A 2-fold cross-validation control will be used in order to gain a relatively low computation time.

```{r, echo=TRUE}
set.seed(3141592)
fitModel <- train(classe~roll_belt+num_window+pitch_belt+magnet_dumbbell_y+magnet_dumbbell_z+pitch_forearm+accel_dumbbell_y+roll_arm+roll_forearm,
                  data=train1,
                  method="rf",
                  trControl=trainControl(method="cv",number=2),
                  prox=TRUE,
                  verbose=TRUE,
                  allowParallel=TRUE)
```

The model is saved for later use, which makes it possible for later use by referencing directly to a variable using one command.

```{r, echo=TRUE}
saveRDS(fitModel, "modelRF.Rds")
fitModel <- readRDS("modelRF.Rds")
```

The accuracy of the model can be obtained by using caret's confusion matrix function applied on train2 (the test set).

```{r, echo=TRUE}
predictions <- predict(fitModel, newdata=train2)
confusionMat <- confusionMatrix(predictions, train2$classe)
confusionMat
```

The resulting accuracy of 99.78% is very high and validates the hypothesis made when eliminating most of the original training variables and only use 9 relatively independent variables. Because the train2 testset is blind (not used while building the predictive model) it gives an unbiased estimate of the out-of-sample error rate equal to 100%-99.78%=0.22%.





